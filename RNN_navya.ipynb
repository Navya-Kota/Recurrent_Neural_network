{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/timeseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-03-18</td>\n",
       "      <td>24.68</td>\n",
       "      <td>164.93</td>\n",
       "      <td>114.73</td>\n",
       "      <td>26.27</td>\n",
       "      <td>19.21</td>\n",
       "      <td>28.87</td>\n",
       "      <td>63.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-03-19</td>\n",
       "      <td>24.18</td>\n",
       "      <td>164.89</td>\n",
       "      <td>114.75</td>\n",
       "      <td>26.22</td>\n",
       "      <td>19.07</td>\n",
       "      <td>27.76</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>23.99</td>\n",
       "      <td>164.63</td>\n",
       "      <td>115.04</td>\n",
       "      <td>25.78</td>\n",
       "      <td>19.01</td>\n",
       "      <td>27.04</td>\n",
       "      <td>59.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-03-25</td>\n",
       "      <td>24.14</td>\n",
       "      <td>163.92</td>\n",
       "      <td>114.85</td>\n",
       "      <td>27.41</td>\n",
       "      <td>19.61</td>\n",
       "      <td>27.84</td>\n",
       "      <td>59.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-03-26</td>\n",
       "      <td>24.44</td>\n",
       "      <td>163.45</td>\n",
       "      <td>114.84</td>\n",
       "      <td>26.86</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.02</td>\n",
       "      <td>60.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      A       B       C      D      E      F      G\n",
       "0  2008-03-18  24.68  164.93  114.73  26.27  19.21  28.87  63.44\n",
       "1  2008-03-19  24.18  164.89  114.75  26.22  19.07  27.76  59.98\n",
       "2  2008-03-20  23.99  164.63  115.04  25.78  19.01  27.04  59.61\n",
       "3  2008-03-25  24.14  163.92  114.85  27.41  19.61  27.84  59.41\n",
       "4  2008-03-26  24.44  163.45  114.84  26.86  19.53  28.02  60.09"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-03-18</th>\n",
       "      <td>2008-03-18</td>\n",
       "      <td>24.68</td>\n",
       "      <td>164.93</td>\n",
       "      <td>114.73</td>\n",
       "      <td>26.27</td>\n",
       "      <td>19.21</td>\n",
       "      <td>28.87</td>\n",
       "      <td>63.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-19</th>\n",
       "      <td>2008-03-19</td>\n",
       "      <td>24.18</td>\n",
       "      <td>164.89</td>\n",
       "      <td>114.75</td>\n",
       "      <td>26.22</td>\n",
       "      <td>19.07</td>\n",
       "      <td>27.76</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-20</th>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>23.99</td>\n",
       "      <td>164.63</td>\n",
       "      <td>115.04</td>\n",
       "      <td>25.78</td>\n",
       "      <td>19.01</td>\n",
       "      <td>27.04</td>\n",
       "      <td>59.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-25</th>\n",
       "      <td>2008-03-25</td>\n",
       "      <td>24.14</td>\n",
       "      <td>163.92</td>\n",
       "      <td>114.85</td>\n",
       "      <td>27.41</td>\n",
       "      <td>19.61</td>\n",
       "      <td>27.84</td>\n",
       "      <td>59.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-26</th>\n",
       "      <td>2008-03-26</td>\n",
       "      <td>24.44</td>\n",
       "      <td>163.45</td>\n",
       "      <td>114.84</td>\n",
       "      <td>26.86</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.02</td>\n",
       "      <td>60.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date      A       B       C      D      E      F      G\n",
       "Date                                                                     \n",
       "2008-03-18  2008-03-18  24.68  164.93  114.73  26.27  19.21  28.87  63.44\n",
       "2008-03-19  2008-03-19  24.18  164.89  114.75  26.22  19.07  27.76  59.98\n",
       "2008-03-20  2008-03-20  23.99  164.63  115.04  25.78  19.01  27.04  59.61\n",
       "2008-03-25  2008-03-25  24.14  163.92  114.85  27.41  19.61  27.84  59.41\n",
       "2008-03-26  2008-03-26  24.44  163.45  114.84  26.86  19.53  28.02  60.09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index=df.Date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['G']\n",
    "df=df.drop(['Date','G'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 24.68 164.93 114.73  26.27  19.21  28.87]\n",
      " [ 24.18 164.89 114.75  26.22  19.07  27.76]\n",
      " [ 23.99 164.63 115.04  25.78  19.01  27.04]\n",
      " [ 24.14 163.92 114.85  27.41  19.61  27.84]\n",
      " [ 24.44 163.45 114.84  26.86  19.53  28.02]\n",
      " [ 24.38 163.46 115.4   27.09  19.72  28.25]\n",
      " [ 24.32 163.22 115.56  27.13  19.63  28.24]\n",
      " [ 24.19 164.02 115.54  26.74  19.55  28.43]\n",
      " [ 23.81 163.59 115.72  27.82  20.21  29.17]\n",
      " [ 24.03 163.32 115.11  28.22  20.42  29.38]\n",
      " [ 24.34 163.34 115.17  28.14  20.36  29.51]]\n",
      "(11, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.values)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y_train=[]\n",
    "values=df.values\n",
    "for i in range (len(values)):\n",
    "    x.append([list(values[i])])\n",
    "    y_train.append([y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[63.44],\n",
       " [59.98],\n",
       " [59.61],\n",
       " [59.41],\n",
       " [60.09],\n",
       " [59.62],\n",
       " [58.65],\n",
       " [59.2],\n",
       " [56.18],\n",
       " [56.64],\n",
       " [57.49]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[24.68, 164.93, 114.73, 26.27, 19.21, 28.87]],\n",
       " [[24.18, 164.89, 114.75, 26.22, 19.07, 27.76]],\n",
       " [[23.99, 164.63, 115.04, 25.78, 19.01, 27.04]],\n",
       " [[24.14, 163.92, 114.85, 27.41, 19.61, 27.84]],\n",
       " [[24.44, 163.45, 114.84, 26.86, 19.53, 28.02]],\n",
       " [[24.38, 163.46, 115.4, 27.09, 19.72, 28.25]],\n",
       " [[24.32, 163.22, 115.56, 27.13, 19.63, 28.24]],\n",
       " [[24.19, 164.02, 115.54, 26.74, 19.55, 28.43]],\n",
       " [[23.81, 163.59, 115.72, 27.82, 20.21, 29.17]],\n",
       " [[24.03, 163.32, 115.11, 28.22, 20.42, 29.38]],\n",
       " [[24.34, 163.34, 115.17, 28.14, 20.36, 29.51]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-03-18</th>\n",
       "      <td>24.68</td>\n",
       "      <td>164.93</td>\n",
       "      <td>114.73</td>\n",
       "      <td>26.27</td>\n",
       "      <td>19.21</td>\n",
       "      <td>28.87</td>\n",
       "      <td>[[24.68, 164.93, 114.73, 26.27, 19.21, 28.87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-19</th>\n",
       "      <td>24.18</td>\n",
       "      <td>164.89</td>\n",
       "      <td>114.75</td>\n",
       "      <td>26.22</td>\n",
       "      <td>19.07</td>\n",
       "      <td>27.76</td>\n",
       "      <td>[[24.18, 164.89, 114.75, 26.22, 19.07, 27.76]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-20</th>\n",
       "      <td>23.99</td>\n",
       "      <td>164.63</td>\n",
       "      <td>115.04</td>\n",
       "      <td>25.78</td>\n",
       "      <td>19.01</td>\n",
       "      <td>27.04</td>\n",
       "      <td>[[23.99, 164.63, 115.04, 25.78, 19.01, 27.04]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-25</th>\n",
       "      <td>24.14</td>\n",
       "      <td>163.92</td>\n",
       "      <td>114.85</td>\n",
       "      <td>27.41</td>\n",
       "      <td>19.61</td>\n",
       "      <td>27.84</td>\n",
       "      <td>[[24.14, 163.92, 114.85, 27.41, 19.61, 27.84]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-26</th>\n",
       "      <td>24.44</td>\n",
       "      <td>163.45</td>\n",
       "      <td>114.84</td>\n",
       "      <td>26.86</td>\n",
       "      <td>19.53</td>\n",
       "      <td>28.02</td>\n",
       "      <td>[[24.44, 163.45, 114.84, 26.86, 19.53, 28.02]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-27</th>\n",
       "      <td>24.38</td>\n",
       "      <td>163.46</td>\n",
       "      <td>115.40</td>\n",
       "      <td>27.09</td>\n",
       "      <td>19.72</td>\n",
       "      <td>28.25</td>\n",
       "      <td>[[24.38, 163.46, 115.4, 27.09, 19.72, 28.25]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-28</th>\n",
       "      <td>24.32</td>\n",
       "      <td>163.22</td>\n",
       "      <td>115.56</td>\n",
       "      <td>27.13</td>\n",
       "      <td>19.63</td>\n",
       "      <td>28.24</td>\n",
       "      <td>[[24.32, 163.22, 115.56, 27.13, 19.63, 28.24]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>24.19</td>\n",
       "      <td>164.02</td>\n",
       "      <td>115.54</td>\n",
       "      <td>26.74</td>\n",
       "      <td>19.55</td>\n",
       "      <td>28.43</td>\n",
       "      <td>[[24.19, 164.02, 115.54, 26.74, 19.55, 28.43]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-01</th>\n",
       "      <td>23.81</td>\n",
       "      <td>163.59</td>\n",
       "      <td>115.72</td>\n",
       "      <td>27.82</td>\n",
       "      <td>20.21</td>\n",
       "      <td>29.17</td>\n",
       "      <td>[[23.81, 163.59, 115.72, 27.82, 20.21, 29.17]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-02</th>\n",
       "      <td>24.03</td>\n",
       "      <td>163.32</td>\n",
       "      <td>115.11</td>\n",
       "      <td>28.22</td>\n",
       "      <td>20.42</td>\n",
       "      <td>29.38</td>\n",
       "      <td>[[24.03, 163.32, 115.11, 28.22, 20.42, 29.38]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-03</th>\n",
       "      <td>24.34</td>\n",
       "      <td>163.34</td>\n",
       "      <td>115.17</td>\n",
       "      <td>28.14</td>\n",
       "      <td>20.36</td>\n",
       "      <td>29.51</td>\n",
       "      <td>[[24.34, 163.34, 115.17, 28.14, 20.36, 29.51]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A       B       C      D      E      F  \\\n",
       "Date                                                     \n",
       "2008-03-18  24.68  164.93  114.73  26.27  19.21  28.87   \n",
       "2008-03-19  24.18  164.89  114.75  26.22  19.07  27.76   \n",
       "2008-03-20  23.99  164.63  115.04  25.78  19.01  27.04   \n",
       "2008-03-25  24.14  163.92  114.85  27.41  19.61  27.84   \n",
       "2008-03-26  24.44  163.45  114.84  26.86  19.53  28.02   \n",
       "2008-03-27  24.38  163.46  115.40  27.09  19.72  28.25   \n",
       "2008-03-28  24.32  163.22  115.56  27.13  19.63  28.24   \n",
       "2008-03-31  24.19  164.02  115.54  26.74  19.55  28.43   \n",
       "2008-04-01  23.81  163.59  115.72  27.82  20.21  29.17   \n",
       "2008-04-02  24.03  163.32  115.11  28.22  20.42  29.38   \n",
       "2008-04-03  24.34  163.34  115.17  28.14  20.36  29.51   \n",
       "\n",
       "                                                         x  \n",
       "Date                                                        \n",
       "2008-03-18  [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87]]  \n",
       "2008-03-19  [[24.18, 164.89, 114.75, 26.22, 19.07, 27.76]]  \n",
       "2008-03-20  [[23.99, 164.63, 115.04, 25.78, 19.01, 27.04]]  \n",
       "2008-03-25  [[24.14, 163.92, 114.85, 27.41, 19.61, 27.84]]  \n",
       "2008-03-26  [[24.44, 163.45, 114.84, 26.86, 19.53, 28.02]]  \n",
       "2008-03-27   [[24.38, 163.46, 115.4, 27.09, 19.72, 28.25]]  \n",
       "2008-03-28  [[24.32, 163.22, 115.56, 27.13, 19.63, 28.24]]  \n",
       "2008-03-31  [[24.19, 164.02, 115.54, 26.74, 19.55, 28.43]]  \n",
       "2008-04-01  [[23.81, 163.59, 115.72, 27.82, 20.21, 29.17]]  \n",
       "2008-04-02  [[24.03, 163.32, 115.11, 28.22, 20.42, 29.38]]  \n",
       "2008-04-03  [[24.34, 163.34, 115.17, 28.14, 20.36, 29.51]]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x']=x\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df['x'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23.99, 164.63, 115.04, 25.78, 19.01, 27.04]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2008-03-18       [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87]]\n",
       "2008-03-19    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-03-20    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-03-25    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-03-26    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-03-27    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-03-28    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-03-31    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-04-01    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-04-02    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "2008-04-03    [[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],...\n",
       "Name: x, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[24.68, 164.93, 114.73, 26.27, 19.21, 28.87],\n",
       " [24.18, 164.89, 114.75, 26.22, 19.07, 27.76],\n",
       " [23.99, 164.63, 115.04, 25.78, 19.01, 27.04]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train_new=pad_sequences(x_train,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 164, 115,  26,  19,  28]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 164, 115,  26,  19,  28],\n",
       "        [ 23, 163, 115,  27,  20,  29]],\n",
       "\n",
       "       [[  0,   0,   0,   0,   0,   0],\n",
       "        [ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 164, 115,  26,  19,  28],\n",
       "        [ 23, 163, 115,  27,  20,  29],\n",
       "        [ 24, 163, 115,  28,  20,  29]],\n",
       "\n",
       "       [[ 24, 164, 114,  26,  19,  28],\n",
       "        [ 24, 164, 114,  26,  19,  27],\n",
       "        [ 23, 164, 115,  25,  19,  27],\n",
       "        [ 24, 163, 114,  27,  19,  27],\n",
       "        [ 24, 163, 114,  26,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 163, 115,  27,  19,  28],\n",
       "        [ 24, 164, 115,  26,  19,  28],\n",
       "        [ 23, 163, 115,  27,  20,  29],\n",
       "        [ 24, 163, 115,  28,  20,  29],\n",
       "        [ 24, 163, 115,  28,  20,  29]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63.44],\n",
       "       [59.98],\n",
       "       [59.61],\n",
       "       [59.41],\n",
       "       [60.09],\n",
       "       [59.62],\n",
       "       [58.65],\n",
       "       [59.2 ],\n",
       "       [56.18],\n",
       "       [56.64],\n",
       "       [57.49]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 6)\n",
      "WARNING:tensorflow:From c:\\users\\naga sri navya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\naga sri navya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\naga sri navya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, input_shape=(11, 6))`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "s=x_train_new.shape\n",
    "print(s)\n",
    "model=Sequential()\n",
    "model.add(LSTM(10,input_dim=s[2],input_length=s[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\naga sri navya\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 3489.2515 - acc: 0.0000e+00 - mean_squared_error: 3489.2515 - mean_absolute_error: 59.0409\n",
      "Epoch 2/300\n",
      "11/11 [==============================] - 0s 998us/step - loss: 2543.4065 - acc: 0.0000e+00 - mean_squared_error: 2543.4065 - mean_absolute_error: 50.4013\n",
      "Epoch 3/300\n",
      "11/11 [==============================] - 0s 855us/step - loss: 958.7842 - acc: 0.0000e+00 - mean_squared_error: 958.7842 - mean_absolute_error: 30.2829\n",
      "Epoch 4/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3406.1523 - acc: 0.0000e+00 - mean_squared_error: 3406.1523 - mean_absolute_error: 58.3303\n",
      "Epoch 5/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3181.0063 - acc: 0.0000e+00 - mean_squared_error: 3181.0063 - mean_absolute_error: 56.3693\n",
      "Epoch 6/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3055.1775 - acc: 0.0000e+00 - mean_squared_error: 3055.1775 - mean_absolute_error: 55.2419\n",
      "Epoch 7/300\n",
      "11/11 [==============================] - 0s 696us/step - loss: 2934.3315 - acc: 0.0000e+00 - mean_squared_error: 2934.3315 - mean_absolute_error: 54.1371\n",
      "Epoch 8/300\n",
      "11/11 [==============================] - 0s 460us/step - loss: 2818.2710 - acc: 0.0000e+00 - mean_squared_error: 2818.2710 - mean_absolute_error: 53.0543\n",
      "Epoch 9/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 2706.8064 - acc: 0.0000e+00 - mean_squared_error: 2706.8064 - mean_absolute_error: 51.9932\n",
      "Epoch 10/300\n",
      "11/11 [==============================] - 0s 526us/step - loss: 2599.7556 - acc: 0.0000e+00 - mean_squared_error: 2599.7556 - mean_absolute_error: 50.9534\n",
      "Epoch 11/300\n",
      "11/11 [==============================] - 0s 455us/step - loss: 2496.9446 - acc: 0.0000e+00 - mean_squared_error: 2496.9446 - mean_absolute_error: 49.9343\n",
      "Epoch 12/300\n",
      "11/11 [==============================] - 0s 634us/step - loss: 2398.2041 - acc: 0.0000e+00 - mean_squared_error: 2398.2041 - mean_absolute_error: 48.9356\n",
      "Epoch 13/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 2303.3748 - acc: 0.0000e+00 - mean_squared_error: 2303.3748 - mean_absolute_error: 47.9569\n",
      "Epoch 14/300\n",
      "11/11 [==============================] - 0s 671us/step - loss: 2212.2998 - acc: 0.0000e+00 - mean_squared_error: 2212.2998 - mean_absolute_error: 46.9978\n",
      "Epoch 15/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 2124.8318 - acc: 0.0000e+00 - mean_squared_error: 2124.8318 - mean_absolute_error: 46.0578\n",
      "Epoch 16/300\n",
      "11/11 [==============================] - 0s 640us/step - loss: 2040.8273 - acc: 0.0000e+00 - mean_squared_error: 2040.8273 - mean_absolute_error: 45.1367\n",
      "Epoch 17/300\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1960.1495 - acc: 0.0000e+00 - mean_squared_error: 1960.1495 - mean_absolute_error: 44.2339\n",
      "Epoch 18/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1882.6665 - acc: 0.0000e+00 - mean_squared_error: 1882.6665 - mean_absolute_error: 43.3493\n",
      "Epoch 19/300\n",
      "11/11 [==============================] - 0s 634us/step - loss: 1808.2518 - acc: 0.0000e+00 - mean_squared_error: 1808.2518 - mean_absolute_error: 42.4823\n",
      "Epoch 20/300\n",
      "11/11 [==============================] - 0s 551us/step - loss: 1736.7839 - acc: 0.0000e+00 - mean_squared_error: 1736.7839 - mean_absolute_error: 41.6326\n",
      "Epoch 21/300\n",
      "11/11 [==============================] - 0s 633us/step - loss: 1668.1464 - acc: 0.0000e+00 - mean_squared_error: 1668.1464 - mean_absolute_error: 40.8000\n",
      "Epoch 22/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1602.2266 - acc: 0.0000e+00 - mean_squared_error: 1602.2266 - mean_absolute_error: 39.9840\n",
      "Epoch 23/300\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1538.9172 - acc: 0.0000e+00 - mean_squared_error: 1538.9172 - mean_absolute_error: 39.1843\n",
      "Epoch 24/300\n",
      "11/11 [==============================] - 0s 632us/step - loss: 1478.1152 - acc: 0.0000e+00 - mean_squared_error: 1478.1152 - mean_absolute_error: 38.4006\n",
      "Epoch 25/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 1419.7206 - acc: 0.0000e+00 - mean_squared_error: 1419.7206 - mean_absolute_error: 37.6326\n",
      "Epoch 26/300\n",
      "11/11 [==============================] - 0s 862us/step - loss: 1363.6388 - acc: 0.0000e+00 - mean_squared_error: 1363.6388 - mean_absolute_error: 36.8799\n",
      "Epoch 27/300\n",
      "11/11 [==============================] - 0s 568us/step - loss: 1309.7776 - acc: 0.0000e+00 - mean_squared_error: 1309.7776 - mean_absolute_error: 36.1423\n",
      "Epoch 28/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 1258.0494 - acc: 0.0000e+00 - mean_squared_error: 1258.0494 - mean_absolute_error: 35.4195\n",
      "Epoch 29/300\n",
      "11/11 [==============================] - 0s 655us/step - loss: 1208.3696 - acc: 0.0000e+00 - mean_squared_error: 1208.3696 - mean_absolute_error: 34.7111\n",
      "Epoch 30/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 1160.6571 - acc: 0.0000e+00 - mean_squared_error: 1160.6571 - mean_absolute_error: 34.0169\n",
      "Epoch 31/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1114.8341 - acc: 0.0000e+00 - mean_squared_error: 1114.8341 - mean_absolute_error: 33.3365\n",
      "Epoch 32/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1070.8254 - acc: 0.0000e+00 - mean_squared_error: 1070.8254 - mean_absolute_error: 32.6698\n",
      "Epoch 33/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1028.5598 - acc: 0.0000e+00 - mean_squared_error: 1028.5598 - mean_absolute_error: 32.0164\n",
      "Epoch 34/300\n",
      "11/11 [==============================] - 0s 594us/step - loss: 987.9678 - acc: 0.0000e+00 - mean_squared_error: 987.9678 - mean_absolute_error: 31.3761\n",
      "Epoch 35/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 948.9833 - acc: 0.0000e+00 - mean_squared_error: 948.9833 - mean_absolute_error: 30.7486\n",
      "Epoch 36/300\n",
      "11/11 [==============================] - 0s 677us/step - loss: 911.5425 - acc: 0.0000e+00 - mean_squared_error: 911.5425 - mean_absolute_error: 30.1336\n",
      "Epoch 37/300\n",
      "11/11 [==============================] - 0s 724us/step - loss: 875.5844 - acc: 0.0000e+00 - mean_squared_error: 875.5844 - mean_absolute_error: 29.5309\n",
      "Epoch 38/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 841.0502 - acc: 0.0000e+00 - mean_squared_error: 841.0502 - mean_absolute_error: 28.9403\n",
      "Epoch 39/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 807.8835 - acc: 0.0000e+00 - mean_squared_error: 807.8835 - mean_absolute_error: 28.3615\n",
      "Epoch 40/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 776.0303 - acc: 0.0000e+00 - mean_squared_error: 776.0303 - mean_absolute_error: 27.7943\n",
      "Epoch 41/300\n",
      "11/11 [==============================] - 0s 705us/step - loss: 745.4385 - acc: 0.0000e+00 - mean_squared_error: 745.4385 - mean_absolute_error: 27.2384\n",
      "Epoch 42/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 716.0579 - acc: 0.0000e+00 - mean_squared_error: 716.0579 - mean_absolute_error: 26.6936\n",
      "Epoch 43/300\n",
      "11/11 [==============================] - 0s 465us/step - loss: 687.8411 - acc: 0.0000e+00 - mean_squared_error: 687.8411 - mean_absolute_error: 26.1597\n",
      "Epoch 44/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 660.7416 - acc: 0.0000e+00 - mean_squared_error: 660.7416 - mean_absolute_error: 25.6366\n",
      "Epoch 45/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 634.7153 - acc: 0.0000e+00 - mean_squared_error: 634.7153 - mean_absolute_error: 25.1238\n",
      "Epoch 46/300\n",
      "11/11 [==============================] - 0s 495us/step - loss: 609.7195 - acc: 0.0000e+00 - mean_squared_error: 609.7195 - mean_absolute_error: 24.6213\n",
      "Epoch 47/300\n",
      "11/11 [==============================] - 0s 369us/step - loss: 585.7135 - acc: 0.0000e+00 - mean_squared_error: 585.7135 - mean_absolute_error: 24.1289\n",
      "Epoch 48/300\n",
      "11/11 [==============================] - 0s 390us/step - loss: 562.6582 - acc: 0.0000e+00 - mean_squared_error: 562.6582 - mean_absolute_error: 23.6463\n",
      "Epoch 49/300\n",
      "11/11 [==============================] - 0s 764us/step - loss: 540.5159 - acc: 0.0000e+00 - mean_squared_error: 540.5159 - mean_absolute_error: 23.1734\n",
      "Epoch 50/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 519.2505 - acc: 0.0000e+00 - mean_squared_error: 519.2505 - mean_absolute_error: 22.7099\n",
      "Epoch 51/300\n",
      "11/11 [==============================] - 0s 510us/step - loss: 498.8270 - acc: 0.0000e+00 - mean_squared_error: 498.8270 - mean_absolute_error: 22.2557\n",
      "Epoch 52/300\n",
      "11/11 [==============================] - 0s 549us/step - loss: 479.2124 - acc: 0.0000e+00 - mean_squared_error: 479.2124 - mean_absolute_error: 21.8106\n",
      "Epoch 53/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 460.3745 - acc: 0.0000e+00 - mean_squared_error: 460.3745 - mean_absolute_error: 21.3744\n",
      "Epoch 54/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 442.2825 - acc: 0.0000e+00 - mean_squared_error: 442.2825 - mean_absolute_error: 20.9469\n",
      "Epoch 55/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 424.9071 - acc: 0.0000e+00 - mean_squared_error: 424.9071 - mean_absolute_error: 20.5280\n",
      "Epoch 56/300\n",
      "11/11 [==============================] - 0s 533us/step - loss: 408.2197 - acc: 0.0000e+00 - mean_squared_error: 408.2197 - mean_absolute_error: 20.1174\n",
      "Epoch 57/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 392.1932 - acc: 0.0000e+00 - mean_squared_error: 392.1932 - mean_absolute_error: 19.7151\n",
      "Epoch 58/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 376.8013 - acc: 0.0000e+00 - mean_squared_error: 376.8013 - mean_absolute_error: 19.3208\n",
      "Epoch 59/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 362.0188 - acc: 0.0000e+00 - mean_squared_error: 362.0188 - mean_absolute_error: 18.9344\n",
      "Epoch 60/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 347.8218 - acc: 0.0000e+00 - mean_squared_error: 347.8218 - mean_absolute_error: 18.5557\n",
      "Epoch 61/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 334.1870 - acc: 0.0000e+00 - mean_squared_error: 334.1870 - mean_absolute_error: 18.1846\n",
      "Epoch 62/300\n",
      "11/11 [==============================] - 0s 437us/step - loss: 321.0922 - acc: 0.0000e+00 - mean_squared_error: 321.0922 - mean_absolute_error: 17.8209\n",
      "Epoch 63/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 308.5158 - acc: 0.0000e+00 - mean_squared_error: 308.5158 - mean_absolute_error: 17.4645\n",
      "Epoch 64/300\n",
      "11/11 [==============================] - 0s 543us/step - loss: 296.4376 - acc: 0.0000e+00 - mean_squared_error: 296.4376 - mean_absolute_error: 17.1152\n",
      "Epoch 65/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 284.8375 - acc: 0.0000e+00 - mean_squared_error: 284.8375 - mean_absolute_error: 16.7729\n",
      "Epoch 66/300\n",
      "11/11 [==============================] - 0s 634us/step - loss: 273.6969 - acc: 0.0000e+00 - mean_squared_error: 273.6969 - mean_absolute_error: 16.4374\n",
      "Epoch 67/300\n",
      "11/11 [==============================] - 0s 673us/step - loss: 262.9975 - acc: 0.0000e+00 - mean_squared_error: 262.9975 - mean_absolute_error: 16.1087\n",
      "Epoch 68/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 252.7217 - acc: 0.0000e+00 - mean_squared_error: 252.7217 - mean_absolute_error: 15.7865\n",
      "Epoch 69/300\n",
      "11/11 [==============================] - 0s 726us/step - loss: 242.8528 - acc: 0.0000e+00 - mean_squared_error: 242.8528 - mean_absolute_error: 15.4708\n",
      "Epoch 70/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 233.3748 - acc: 0.0000e+00 - mean_squared_error: 233.3748 - mean_absolute_error: 15.1613\n",
      "Epoch 71/300\n",
      "11/11 [==============================] - 0s 908us/step - loss: 224.2722 - acc: 0.0000e+00 - mean_squared_error: 224.2722 - mean_absolute_error: 14.8581\n",
      "Epoch 72/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 215.5300 - acc: 0.0000e+00 - mean_squared_error: 215.5300 - mean_absolute_error: 14.5610\n",
      "Epoch 73/300\n",
      "11/11 [==============================] - 0s 533us/step - loss: 207.1340 - acc: 0.0000e+00 - mean_squared_error: 207.1340 - mean_absolute_error: 14.2697\n",
      "Epoch 74/300\n",
      "11/11 [==============================] - 0s 812us/step - loss: 199.0704 - acc: 0.0000e+00 - mean_squared_error: 199.0704 - mean_absolute_error: 13.9843\n",
      "Epoch 75/300\n",
      "11/11 [==============================] - 0s 634us/step - loss: 191.3262 - acc: 0.0000e+00 - mean_squared_error: 191.3262 - mean_absolute_error: 13.7047\n",
      "Epoch 76/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 183.8886 - acc: 0.0000e+00 - mean_squared_error: 183.8886 - mean_absolute_error: 13.4306\n",
      "Epoch 77/300\n",
      "11/11 [==============================] - 0s 565us/step - loss: 176.7456 - acc: 0.0000e+00 - mean_squared_error: 176.7456 - mean_absolute_error: 13.1619\n",
      "Epoch 78/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 169.8853 - acc: 0.0000e+00 - mean_squared_error: 169.8853 - mean_absolute_error: 12.8987\n",
      "Epoch 79/300\n",
      "11/11 [==============================] - 0s 537us/step - loss: 163.2969 - acc: 0.0000e+00 - mean_squared_error: 163.2969 - mean_absolute_error: 12.6407\n",
      "Epoch 80/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 156.9692 - acc: 0.0000e+00 - mean_squared_error: 156.9692 - mean_absolute_error: 12.3879\n",
      "Epoch 81/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 150.8922 - acc: 0.0000e+00 - mean_squared_error: 150.8922 - mean_absolute_error: 12.1402\n",
      "Epoch 82/300\n",
      "11/11 [==============================] - 0s 647us/step - loss: 145.0559 - acc: 0.0000e+00 - mean_squared_error: 145.0559 - mean_absolute_error: 11.8974\n",
      "Epoch 83/300\n",
      "11/11 [==============================] - 0s 534us/step - loss: 139.4506 - acc: 0.0000e+00 - mean_squared_error: 139.4506 - mean_absolute_error: 11.6594\n",
      "Epoch 84/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 134.0673 - acc: 0.0000e+00 - mean_squared_error: 134.0673 - mean_absolute_error: 11.4262\n",
      "Epoch 85/300\n",
      "11/11 [==============================] - 0s 825us/step - loss: 128.8972 - acc: 0.0000e+00 - mean_squared_error: 128.8972 - mean_absolute_error: 11.1977\n",
      "Epoch 86/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 123.9319 - acc: 0.0000e+00 - mean_squared_error: 123.9319 - mean_absolute_error: 10.9738\n",
      "Epoch 87/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 119.1631 - acc: 0.0000e+00 - mean_squared_error: 119.1631 - mean_absolute_error: 10.7543\n",
      "Epoch 88/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 114.5832 - acc: 0.0000e+00 - mean_squared_error: 114.5832 - mean_absolute_error: 10.5392\n",
      "Epoch 89/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 110.1847 - acc: 0.0000e+00 - mean_squared_error: 110.1847 - mean_absolute_error: 10.3284\n",
      "Epoch 90/300\n",
      "11/11 [==============================] - 0s 707us/step - loss: 105.9603 - acc: 0.0000e+00 - mean_squared_error: 105.9603 - mean_absolute_error: 10.1218\n",
      "Epoch 91/300\n",
      "11/11 [==============================] - 0s 684us/step - loss: 101.9031 - acc: 0.0000e+00 - mean_squared_error: 101.9031 - mean_absolute_error: 9.9194\n",
      "Epoch 92/300\n",
      "11/11 [==============================] - 0s 646us/step - loss: 98.0067 - acc: 0.0000e+00 - mean_squared_error: 98.0067 - mean_absolute_error: 9.7210\n",
      "Epoch 93/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 94.2646 - acc: 0.0000e+00 - mean_squared_error: 94.2646 - mean_absolute_error: 9.5266\n",
      "Epoch 94/300\n",
      "11/11 [==============================] - 0s 483us/step - loss: 90.6707 - acc: 0.0000e+00 - mean_squared_error: 90.6707 - mean_absolute_error: 9.3361\n",
      "Epoch 95/300\n",
      "11/11 [==============================] - 0s 680us/step - loss: 87.2190 - acc: 0.0000e+00 - mean_squared_error: 87.2190 - mean_absolute_error: 9.1493\n",
      "Epoch 96/300\n",
      "11/11 [==============================] - 0s 632us/step - loss: 83.9041 - acc: 0.0000e+00 - mean_squared_error: 83.9041 - mean_absolute_error: 8.9664\n",
      "Epoch 97/300\n",
      "11/11 [==============================] - 0s 543us/step - loss: 80.7204 - acc: 0.0000e+00 - mean_squared_error: 80.7204 - mean_absolute_error: 8.7870\n",
      "Epoch 98/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 77.6628 - acc: 0.0000e+00 - mean_squared_error: 77.6628 - mean_absolute_error: 8.6113\n",
      "Epoch 99/300\n",
      "11/11 [==============================] - 0s 515us/step - loss: 74.7263 - acc: 0.0000e+00 - mean_squared_error: 74.7263 - mean_absolute_error: 8.4391\n",
      "Epoch 100/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 71.9061 - acc: 0.0000e+00 - mean_squared_error: 71.9061 - mean_absolute_error: 8.2703\n",
      "Epoch 101/300\n",
      "11/11 [==============================] - 0s 573us/step - loss: 69.1976 - acc: 0.0000e+00 - mean_squared_error: 69.1976 - mean_absolute_error: 8.1049\n",
      "Epoch 102/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 66.5963 - acc: 0.0000e+00 - mean_squared_error: 66.5963 - mean_absolute_error: 7.9428\n",
      "Epoch 103/300\n",
      "11/11 [==============================] - 0s 604us/step - loss: 64.0980 - acc: 0.0000e+00 - mean_squared_error: 64.0980 - mean_absolute_error: 7.7839\n",
      "Epoch 104/300\n",
      "11/11 [==============================] - 0s 451us/step - loss: 61.6987 - acc: 0.0000e+00 - mean_squared_error: 61.6987 - mean_absolute_error: 7.6282\n",
      "Epoch 105/300\n",
      "11/11 [==============================] - 0s 575us/step - loss: 59.3944 - acc: 0.0000e+00 - mean_squared_error: 59.3944 - mean_absolute_error: 7.4757\n",
      "Epoch 106/300\n",
      "11/11 [==============================] - 0s 633us/step - loss: 57.1813 - acc: 0.0000e+00 - mean_squared_error: 57.1813 - mean_absolute_error: 7.3262\n",
      "Epoch 107/300\n",
      "11/11 [==============================] - 0s 452us/step - loss: 55.0559 - acc: 0.0000e+00 - mean_squared_error: 55.0559 - mean_absolute_error: 7.1796\n",
      "Epoch 108/300\n",
      "11/11 [==============================] - 0s 609us/step - loss: 53.0146 - acc: 0.0000e+00 - mean_squared_error: 53.0146 - mean_absolute_error: 7.0360\n",
      "Epoch 109/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 51.0542 - acc: 0.0000e+00 - mean_squared_error: 51.0542 - mean_absolute_error: 6.8953\n",
      "Epoch 110/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 49.1714 - acc: 0.0000e+00 - mean_squared_error: 49.1714 - mean_absolute_error: 6.7574\n",
      "Epoch 111/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 47.3632 - acc: 0.0000e+00 - mean_squared_error: 47.3632 - mean_absolute_error: 6.6223\n",
      "Epoch 112/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 45.6265 - acc: 0.0000e+00 - mean_squared_error: 45.6265 - mean_absolute_error: 6.4898\n",
      "Epoch 113/300\n",
      "11/11 [==============================] - 0s 505us/step - loss: 43.9587 - acc: 0.0000e+00 - mean_squared_error: 43.9587 - mean_absolute_error: 6.3600\n",
      "Epoch 114/300\n",
      "11/11 [==============================] - 0s 663us/step - loss: 42.3568 - acc: 0.0000e+00 - mean_squared_error: 42.3568 - mean_absolute_error: 6.2328\n",
      "Epoch 115/300\n",
      "11/11 [==============================] - 0s 546us/step - loss: 40.8184 - acc: 0.0000e+00 - mean_squared_error: 40.8184 - mean_absolute_error: 6.1082\n",
      "Epoch 116/300\n",
      "11/11 [==============================] - 0s 997us/step - loss: 39.3410 - acc: 0.0000e+00 - mean_squared_error: 39.3410 - mean_absolute_error: 5.9860\n",
      "Epoch 117/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.9220 - acc: 0.0000e+00 - mean_squared_error: 37.9220 - mean_absolute_error: 5.8663\n",
      "Epoch 118/300\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.5593 - acc: 0.0000e+00 - mean_squared_error: 36.5593 - mean_absolute_error: 5.7490\n",
      "Epoch 119/300\n",
      "11/11 [==============================] - 0s 859us/step - loss: 35.2505 - acc: 0.0000e+00 - mean_squared_error: 35.2505 - mean_absolute_error: 5.6340\n",
      "Epoch 120/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 33.9935 - acc: 0.0000e+00 - mean_squared_error: 33.9935 - mean_absolute_error: 5.5213\n",
      "Epoch 121/300\n",
      "11/11 [==============================] - 0s 815us/step - loss: 32.7863 - acc: 0.0000e+00 - mean_squared_error: 32.7863 - mean_absolute_error: 5.4109\n",
      "Epoch 122/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 31.6269 - acc: 0.0000e+00 - mean_squared_error: 31.6269 - mean_absolute_error: 5.3027\n",
      "Epoch 123/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 30.5134 - acc: 0.0000e+00 - mean_squared_error: 30.5134 - mean_absolute_error: 5.1966\n",
      "Epoch 124/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 29.4440 - acc: 0.0000e+00 - mean_squared_error: 29.4440 - mean_absolute_error: 5.0927\n",
      "Epoch 125/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 28.4170 - acc: 0.0000e+00 - mean_squared_error: 28.4170 - mean_absolute_error: 4.9908\n",
      "Epoch 126/300\n",
      "11/11 [==============================] - 0s 573us/step - loss: 27.4306 - acc: 0.0000e+00 - mean_squared_error: 27.4306 - mean_absolute_error: 4.8910\n",
      "Epoch 127/300\n",
      "11/11 [==============================] - 0s 549us/step - loss: 26.4833 - acc: 0.0000e+00 - mean_squared_error: 26.4833 - mean_absolute_error: 4.7932\n",
      "Epoch 128/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 25.5735 - acc: 0.0000e+00 - mean_squared_error: 25.5735 - mean_absolute_error: 4.6973\n",
      "Epoch 129/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 24.6998 - acc: 0.0000e+00 - mean_squared_error: 24.6998 - mean_absolute_error: 4.6034\n",
      "Epoch 130/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 23.8606 - acc: 0.0000e+00 - mean_squared_error: 23.8606 - mean_absolute_error: 4.5113\n",
      "Epoch 131/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 23.0547 - acc: 0.0000e+00 - mean_squared_error: 23.0547 - mean_absolute_error: 4.4211\n",
      "Epoch 132/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 22.2806 - acc: 0.0000e+00 - mean_squared_error: 22.2806 - mean_absolute_error: 4.3327\n",
      "Epoch 133/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 21.5373 - acc: 0.0000e+00 - mean_squared_error: 21.5373 - mean_absolute_error: 4.2460\n",
      "Epoch 134/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 20.8233 - acc: 0.0000e+00 - mean_squared_error: 20.8233 - mean_absolute_error: 4.1611\n",
      "Epoch 135/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 20.1377 - acc: 0.0000e+00 - mean_squared_error: 20.1377 - mean_absolute_error: 4.0779\n",
      "Epoch 136/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 19.4792 - acc: 0.0000e+00 - mean_squared_error: 19.4792 - mean_absolute_error: 3.9963\n",
      "Epoch 137/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 18.8467 - acc: 0.0000e+00 - mean_squared_error: 18.8467 - mean_absolute_error: 3.9164\n",
      "Epoch 138/300\n",
      "11/11 [==============================] - 0s 604us/step - loss: 18.2394 - acc: 0.0000e+00 - mean_squared_error: 18.2394 - mean_absolute_error: 3.8381\n",
      "Epoch 139/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 17.6560 - acc: 0.0000e+00 - mean_squared_error: 17.6560 - mean_absolute_error: 3.7613\n",
      "Epoch 140/300\n",
      "11/11 [==============================] - 0s 543us/step - loss: 17.0958 - acc: 0.0000e+00 - mean_squared_error: 17.0958 - mean_absolute_error: 3.6861\n",
      "Epoch 141/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 16.5577 - acc: 0.0000e+00 - mean_squared_error: 16.5577 - mean_absolute_error: 3.6124\n",
      "Epoch 142/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 16.0410 - acc: 0.0000e+00 - mean_squared_error: 16.0410 - mean_absolute_error: 3.5401\n",
      "Epoch 143/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 15.5447 - acc: 0.0000e+00 - mean_squared_error: 15.5447 - mean_absolute_error: 3.4693\n",
      "Epoch 144/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 15.0681 - acc: 0.0000e+00 - mean_squared_error: 15.0681 - mean_absolute_error: 3.3999\n",
      "Epoch 145/300\n",
      "11/11 [==============================] - 0s 437us/step - loss: 14.6104 - acc: 0.0000e+00 - mean_squared_error: 14.6104 - mean_absolute_error: 3.3319\n",
      "Epoch 146/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 14.1707 - acc: 0.0000e+00 - mean_squared_error: 14.1707 - mean_absolute_error: 3.2653\n",
      "Epoch 147/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 13.7485 - acc: 0.0000e+00 - mean_squared_error: 13.7485 - mean_absolute_error: 3.2000\n",
      "Epoch 148/300\n",
      "11/11 [==============================] - 0s 363us/step - loss: 13.3430 - acc: 0.0000e+00 - mean_squared_error: 13.3430 - mean_absolute_error: 3.1360\n",
      "Epoch 149/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 12.9536 - acc: 0.0000e+00 - mean_squared_error: 12.9536 - mean_absolute_error: 3.0733\n",
      "Epoch 150/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 12.5795 - acc: 0.0000e+00 - mean_squared_error: 12.5795 - mean_absolute_error: 3.0118\n",
      "Epoch 151/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 12.2204 - acc: 0.0000e+00 - mean_squared_error: 12.2204 - mean_absolute_error: 2.9516\n",
      "Epoch 152/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 11.8754 - acc: 0.0000e+00 - mean_squared_error: 11.8754 - mean_absolute_error: 2.9010\n",
      "Epoch 153/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 11.5440 - acc: 0.0000e+00 - mean_squared_error: 11.5440 - mean_absolute_error: 2.8537\n",
      "Epoch 154/300\n",
      "11/11 [==============================] - 0s 824us/step - loss: 11.2258 - acc: 0.0000e+00 - mean_squared_error: 11.2258 - mean_absolute_error: 2.8073\n",
      "Epoch 155/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 10.9202 - acc: 0.0000e+00 - mean_squared_error: 10.9202 - mean_absolute_error: 2.7618\n",
      "Epoch 156/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 10.6267 - acc: 0.0000e+00 - mean_squared_error: 10.6267 - mean_absolute_error: 2.7173\n",
      "Epoch 157/300\n",
      "11/11 [==============================] - 0s 862us/step - loss: 10.3449 - acc: 0.0000e+00 - mean_squared_error: 10.3449 - mean_absolute_error: 2.6736\n",
      "Epoch 158/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 10.0741 - acc: 0.0000e+00 - mean_squared_error: 10.0741 - mean_absolute_error: 2.6308\n",
      "Epoch 159/300\n",
      "11/11 [==============================] - 0s 538us/step - loss: 9.8142 - acc: 0.0000e+00 - mean_squared_error: 9.8142 - mean_absolute_error: 2.5889\n",
      "Epoch 160/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 9.5645 - acc: 0.0000e+00 - mean_squared_error: 9.5645 - mean_absolute_error: 2.5511\n",
      "Epoch 161/300\n",
      "11/11 [==============================] - 0s 591us/step - loss: 9.3247 - acc: 0.0000e+00 - mean_squared_error: 9.3247 - mean_absolute_error: 2.5198\n",
      "Epoch 162/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 9.0943 - acc: 0.0000e+00 - mean_squared_error: 9.0943 - mean_absolute_error: 2.4891\n",
      "Epoch 163/300\n",
      "11/11 [==============================] - 0s 699us/step - loss: 8.8731 - acc: 0.0000e+00 - mean_squared_error: 8.8731 - mean_absolute_error: 2.4590\n",
      "Epoch 164/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 8.6607 - acc: 0.0000e+00 - mean_squared_error: 8.6607 - mean_absolute_error: 2.4296\n",
      "Epoch 165/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 8.4567 - acc: 0.0000e+00 - mean_squared_error: 8.4567 - mean_absolute_error: 2.4007\n",
      "Epoch 166/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 8.2608 - acc: 0.0000e+00 - mean_squared_error: 8.2608 - mean_absolute_error: 2.3724\n",
      "Epoch 167/300\n",
      "11/11 [==============================] - 0s 542us/step - loss: 8.0726 - acc: 0.0000e+00 - mean_squared_error: 8.0726 - mean_absolute_error: 2.3446\n",
      "Epoch 168/300\n",
      "11/11 [==============================] - 0s 997us/step - loss: 7.8918 - acc: 0.0000e+00 - mean_squared_error: 7.8918 - mean_absolute_error: 2.3174\n",
      "Epoch 169/300\n",
      "11/11 [==============================] - 0s 997us/step - loss: 7.7183 - acc: 0.0000e+00 - mean_squared_error: 7.7183 - mean_absolute_error: 2.2908\n",
      "Epoch 170/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 7.5516 - acc: 0.0000e+00 - mean_squared_error: 7.5516 - mean_absolute_error: 2.2647\n",
      "Epoch 171/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 7.3915 - acc: 0.0000e+00 - mean_squared_error: 7.3915 - mean_absolute_error: 2.2391\n",
      "Epoch 172/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 7.2377 - acc: 0.0000e+00 - mean_squared_error: 7.2377 - mean_absolute_error: 2.2140\n",
      "Epoch 173/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 7.0900 - acc: 0.0000e+00 - mean_squared_error: 7.0900 - mean_absolute_error: 2.1894\n",
      "Epoch 174/300\n",
      "11/11 [==============================] - 0s 606us/step - loss: 6.9482 - acc: 0.0000e+00 - mean_squared_error: 6.9482 - mean_absolute_error: 2.1653\n",
      "Epoch 175/300\n",
      "11/11 [==============================] - 0s 507us/step - loss: 6.8120 - acc: 0.0000e+00 - mean_squared_error: 6.8120 - mean_absolute_error: 2.1417\n",
      "Epoch 176/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 6.6812 - acc: 0.0000e+00 - mean_squared_error: 6.6812 - mean_absolute_error: 2.1186\n",
      "Epoch 177/300\n",
      "11/11 [==============================] - 0s 483us/step - loss: 6.5556 - acc: 0.0000e+00 - mean_squared_error: 6.5556 - mean_absolute_error: 2.0959\n",
      "Epoch 178/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 6.4349 - acc: 0.0000e+00 - mean_squared_error: 6.4349 - mean_absolute_error: 2.0737\n",
      "Epoch 179/300\n",
      "11/11 [==============================] - 0s 724us/step - loss: 6.3190 - acc: 0.0000e+00 - mean_squared_error: 6.3190 - mean_absolute_error: 2.0519\n",
      "Epoch 180/300\n",
      "11/11 [==============================] - 0s 615us/step - loss: 6.2077 - acc: 0.0000e+00 - mean_squared_error: 6.2077 - mean_absolute_error: 2.0306\n",
      "Epoch 181/300\n",
      "11/11 [==============================] - 0s 726us/step - loss: 6.1009 - acc: 0.0000e+00 - mean_squared_error: 6.1009 - mean_absolute_error: 2.0132\n",
      "Epoch 182/300\n",
      "11/11 [==============================] - 0s 578us/step - loss: 5.9982 - acc: 0.0000e+00 - mean_squared_error: 5.9982 - mean_absolute_error: 1.9985\n",
      "Epoch 183/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 5.8996 - acc: 0.0000e+00 - mean_squared_error: 5.8996 - mean_absolute_error: 1.9842\n",
      "Epoch 184/300\n",
      "11/11 [==============================] - 0s 813us/step - loss: 5.8049 - acc: 0.0000e+00 - mean_squared_error: 5.8049 - mean_absolute_error: 1.9701\n",
      "Epoch 185/300\n",
      "11/11 [==============================] - 0s 531us/step - loss: 5.7140 - acc: 0.0000e+00 - mean_squared_error: 5.7140 - mean_absolute_error: 1.9563\n",
      "Epoch 186/300\n",
      "11/11 [==============================] - 0s 773us/step - loss: 5.6267 - acc: 0.0000e+00 - mean_squared_error: 5.6267 - mean_absolute_error: 1.9428\n",
      "Epoch 187/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 5.5428 - acc: 0.0000e+00 - mean_squared_error: 5.5428 - mean_absolute_error: 1.9296\n",
      "Epoch 188/300\n",
      "11/11 [==============================] - 0s 812us/step - loss: 5.4623 - acc: 0.0000e+00 - mean_squared_error: 5.4623 - mean_absolute_error: 1.9166\n",
      "Epoch 189/300\n",
      "11/11 [==============================] - 0s 636us/step - loss: 5.3849 - acc: 0.0000e+00 - mean_squared_error: 5.3849 - mean_absolute_error: 1.9039\n",
      "Epoch 190/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 5.3106 - acc: 0.0000e+00 - mean_squared_error: 5.3106 - mean_absolute_error: 1.8915\n",
      "Epoch 191/300\n",
      "11/11 [==============================] - 0s 998us/step - loss: 5.2392 - acc: 0.0000e+00 - mean_squared_error: 5.2392 - mean_absolute_error: 1.8793\n",
      "Epoch 192/300\n",
      "11/11 [==============================] - 0s 489us/step - loss: 5.1707 - acc: 0.0000e+00 - mean_squared_error: 5.1707 - mean_absolute_error: 1.8673\n",
      "Epoch 193/300\n",
      "11/11 [==============================] - 0s 815us/step - loss: 5.1049 - acc: 0.0000e+00 - mean_squared_error: 5.1049 - mean_absolute_error: 1.8556\n",
      "Epoch 194/300\n",
      "11/11 [==============================] - 0s 872us/step - loss: 5.0417 - acc: 0.0000e+00 - mean_squared_error: 5.0417 - mean_absolute_error: 1.8441\n",
      "Epoch 195/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 4.9810 - acc: 0.0000e+00 - mean_squared_error: 4.9810 - mean_absolute_error: 1.8329\n",
      "Epoch 196/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 4.9227 - acc: 0.0000e+00 - mean_squared_error: 4.9227 - mean_absolute_error: 1.8218\n",
      "Epoch 197/300\n",
      "11/11 [==============================] - 0s 724us/step - loss: 4.8667 - acc: 0.0000e+00 - mean_squared_error: 4.8667 - mean_absolute_error: 1.8110\n",
      "Epoch 198/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 4.8129 - acc: 0.0000e+00 - mean_squared_error: 4.8129 - mean_absolute_error: 1.8004\n",
      "Epoch 199/300\n",
      "11/11 [==============================] - 0s 538us/step - loss: 4.7612 - acc: 0.0000e+00 - mean_squared_error: 4.7612 - mean_absolute_error: 1.7900\n",
      "Epoch 200/300\n",
      "11/11 [==============================] - 0s 634us/step - loss: 4.7116 - acc: 0.0000e+00 - mean_squared_error: 4.7116 - mean_absolute_error: 1.7799\n",
      "Epoch 201/300\n",
      "11/11 [==============================] - 0s 905us/step - loss: 4.6640 - acc: 0.0000e+00 - mean_squared_error: 4.6640 - mean_absolute_error: 1.7699\n",
      "Epoch 202/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 4.6183 - acc: 0.0000e+00 - mean_squared_error: 4.6183 - mean_absolute_error: 1.7601\n",
      "Epoch 203/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 4.5743 - acc: 0.0000e+00 - mean_squared_error: 4.5743 - mean_absolute_error: 1.7506\n",
      "Epoch 204/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 4.5321 - acc: 0.0000e+00 - mean_squared_error: 4.5321 - mean_absolute_error: 1.7412\n",
      "Epoch 205/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 4.4916 - acc: 0.0000e+00 - mean_squared_error: 4.4916 - mean_absolute_error: 1.7320\n",
      "Epoch 206/300\n",
      "11/11 [==============================] - 0s 719us/step - loss: 4.4527 - acc: 0.0000e+00 - mean_squared_error: 4.4527 - mean_absolute_error: 1.7230\n",
      "Epoch 207/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 4.4153 - acc: 0.0000e+00 - mean_squared_error: 4.4153 - mean_absolute_error: 1.7141\n",
      "Epoch 208/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 4.3794 - acc: 0.0000e+00 - mean_squared_error: 4.3794 - mean_absolute_error: 1.7055\n",
      "Epoch 209/300\n",
      "11/11 [==============================] - 0s 632us/step - loss: 4.3449 - acc: 0.0000e+00 - mean_squared_error: 4.3449 - mean_absolute_error: 1.6970\n",
      "Epoch 210/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 4.3118 - acc: 0.0000e+00 - mean_squared_error: 4.3118 - mean_absolute_error: 1.6887\n",
      "Epoch 211/300\n",
      "11/11 [==============================] - 0s 630us/step - loss: 4.2800 - acc: 0.0000e+00 - mean_squared_error: 4.2800 - mean_absolute_error: 1.6805\n",
      "Epoch 212/300\n",
      "11/11 [==============================] - 0s 813us/step - loss: 4.2494 - acc: 0.0000e+00 - mean_squared_error: 4.2494 - mean_absolute_error: 1.6725\n",
      "Epoch 213/300\n",
      "11/11 [==============================] - 0s 709us/step - loss: 4.2201 - acc: 0.0000e+00 - mean_squared_error: 4.2201 - mean_absolute_error: 1.6647\n",
      "Epoch 214/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 4.1919 - acc: 0.0000e+00 - mean_squared_error: 4.1919 - mean_absolute_error: 1.6571\n",
      "Epoch 215/300\n",
      "11/11 [==============================] - 0s 789us/step - loss: 4.1649 - acc: 0.0000e+00 - mean_squared_error: 4.1649 - mean_absolute_error: 1.6495\n",
      "Epoch 216/300\n",
      "11/11 [==============================] - 0s 770us/step - loss: 4.1389 - acc: 0.0000e+00 - mean_squared_error: 4.1389 - mean_absolute_error: 1.6422\n",
      "Epoch 217/300\n",
      "11/11 [==============================] - 0s 636us/step - loss: 4.1139 - acc: 0.0000e+00 - mean_squared_error: 4.1139 - mean_absolute_error: 1.6350\n",
      "Epoch 218/300\n",
      "11/11 [==============================] - 0s 818us/step - loss: 4.0900 - acc: 0.0000e+00 - mean_squared_error: 4.0900 - mean_absolute_error: 1.6279\n",
      "Epoch 219/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 4.0669 - acc: 0.0000e+00 - mean_squared_error: 4.0669 - mean_absolute_error: 1.6210\n",
      "Epoch 220/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 4.0448 - acc: 0.0000e+00 - mean_squared_error: 4.0448 - mean_absolute_error: 1.6142\n",
      "Epoch 221/300\n",
      "11/11 [==============================] - 0s 767us/step - loss: 4.0236 - acc: 0.0000e+00 - mean_squared_error: 4.0236 - mean_absolute_error: 1.6075\n",
      "Epoch 222/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 4.0032 - acc: 0.0000e+00 - mean_squared_error: 4.0032 - mean_absolute_error: 1.6010\n",
      "Epoch 223/300\n",
      "11/11 [==============================] - 0s 785us/step - loss: 3.9836 - acc: 0.0000e+00 - mean_squared_error: 3.9836 - mean_absolute_error: 1.5946\n",
      "Epoch 224/300\n",
      "11/11 [==============================] - 0s 505us/step - loss: 3.9648 - acc: 0.0000e+00 - mean_squared_error: 3.9648 - mean_absolute_error: 1.5883\n",
      "Epoch 225/300\n",
      "11/11 [==============================] - 0s 999us/step - loss: 3.9468 - acc: 0.0000e+00 - mean_squared_error: 3.9468 - mean_absolute_error: 1.5822\n",
      "Epoch 226/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.9294 - acc: 0.0000e+00 - mean_squared_error: 3.9294 - mean_absolute_error: 1.5762\n",
      "Epoch 227/300\n",
      "11/11 [==============================] - 0s 784us/step - loss: 3.9128 - acc: 0.0000e+00 - mean_squared_error: 3.9128 - mean_absolute_error: 1.5703\n",
      "Epoch 228/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.8967 - acc: 0.0000e+00 - mean_squared_error: 3.8967 - mean_absolute_error: 1.5645\n",
      "Epoch 229/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.8814 - acc: 0.0000e+00 - mean_squared_error: 3.8814 - mean_absolute_error: 1.5588\n",
      "Epoch 230/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.8666 - acc: 0.0000e+00 - mean_squared_error: 3.8666 - mean_absolute_error: 1.5533\n",
      "Epoch 231/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.8524 - acc: 0.0000e+00 - mean_squared_error: 3.8524 - mean_absolute_error: 1.5478\n",
      "Epoch 232/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.8388 - acc: 0.0000e+00 - mean_squared_error: 3.8388 - mean_absolute_error: 1.5425\n",
      "Epoch 233/300\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3.8258 - acc: 0.0000e+00 - mean_squared_error: 3.8258 - mean_absolute_error: 1.5373\n",
      "Epoch 234/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.8132 - acc: 0.0000e+00 - mean_squared_error: 3.8132 - mean_absolute_error: 1.5322\n",
      "Epoch 235/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 3.8011 - acc: 0.0000e+00 - mean_squared_error: 3.8011 - mean_absolute_error: 1.5271\n",
      "Epoch 236/300\n",
      "11/11 [==============================] - 0s 908us/step - loss: 3.7896 - acc: 0.0000e+00 - mean_squared_error: 3.7896 - mean_absolute_error: 1.5222\n",
      "Epoch 237/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 3.7784 - acc: 0.0000e+00 - mean_squared_error: 3.7784 - mean_absolute_error: 1.5174\n",
      "Epoch 238/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.7678 - acc: 0.0000e+00 - mean_squared_error: 3.7678 - mean_absolute_error: 1.5127\n",
      "Epoch 239/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.7575 - acc: 0.0000e+00 - mean_squared_error: 3.7575 - mean_absolute_error: 1.5081\n",
      "Epoch 240/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.7476 - acc: 0.0000e+00 - mean_squared_error: 3.7476 - mean_absolute_error: 1.5035\n",
      "Epoch 241/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.7382 - acc: 0.0000e+00 - mean_squared_error: 3.7382 - mean_absolute_error: 1.4991\n",
      "Epoch 242/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.7291 - acc: 0.0000e+00 - mean_squared_error: 3.7291 - mean_absolute_error: 1.4947\n",
      "Epoch 243/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.7204 - acc: 0.0000e+00 - mean_squared_error: 3.7204 - mean_absolute_error: 1.4921\n",
      "Epoch 244/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.7120 - acc: 0.0000e+00 - mean_squared_error: 3.7120 - mean_absolute_error: 1.4896\n",
      "Epoch 245/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.7039 - acc: 0.0000e+00 - mean_squared_error: 3.7039 - mean_absolute_error: 1.4871\n",
      "Epoch 246/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.6962 - acc: 0.0000e+00 - mean_squared_error: 3.6962 - mean_absolute_error: 1.4847\n",
      "Epoch 247/300\n",
      "11/11 [==============================] - 0s 615us/step - loss: 3.6888 - acc: 0.0000e+00 - mean_squared_error: 3.6888 - mean_absolute_error: 1.4824\n",
      "Epoch 248/300\n",
      "11/11 [==============================] - 0s 546us/step - loss: 3.6816 - acc: 0.0000e+00 - mean_squared_error: 3.6816 - mean_absolute_error: 1.4800\n",
      "Epoch 249/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.6748 - acc: 0.0000e+00 - mean_squared_error: 3.6748 - mean_absolute_error: 1.4778\n",
      "Epoch 250/300\n",
      "11/11 [==============================] - 0s 453us/step - loss: 3.6682 - acc: 0.0000e+00 - mean_squared_error: 3.6682 - mean_absolute_error: 1.4755\n",
      "Epoch 251/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.6619 - acc: 0.0000e+00 - mean_squared_error: 3.6619 - mean_absolute_error: 1.4734\n",
      "Epoch 252/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.6558 - acc: 0.0000e+00 - mean_squared_error: 3.6558 - mean_absolute_error: 1.4712\n",
      "Epoch 253/300\n",
      "11/11 [==============================] - 0s 678us/step - loss: 3.6500 - acc: 0.0000e+00 - mean_squared_error: 3.6500 - mean_absolute_error: 1.4691\n",
      "Epoch 254/300\n",
      "11/11 [==============================] - 0s 543us/step - loss: 3.6444 - acc: 0.0000e+00 - mean_squared_error: 3.6444 - mean_absolute_error: 1.4671\n",
      "Epoch 255/300\n",
      "11/11 [==============================] - 0s 473us/step - loss: 3.6390 - acc: 0.0000e+00 - mean_squared_error: 3.6390 - mean_absolute_error: 1.4651\n",
      "Epoch 256/300\n",
      "11/11 [==============================] - 0s 815us/step - loss: 3.6339 - acc: 0.0000e+00 - mean_squared_error: 3.6339 - mean_absolute_error: 1.4631\n",
      "Epoch 257/300\n",
      "11/11 [==============================] - 0s 729us/step - loss: 3.6289 - acc: 0.0000e+00 - mean_squared_error: 3.6289 - mean_absolute_error: 1.4612\n",
      "Epoch 258/300\n",
      "11/11 [==============================] - 0s 680us/step - loss: 3.6241 - acc: 0.0000e+00 - mean_squared_error: 3.6241 - mean_absolute_error: 1.4593\n",
      "Epoch 259/300\n",
      "11/11 [==============================] - 0s 641us/step - loss: 3.6196 - acc: 0.0000e+00 - mean_squared_error: 3.6196 - mean_absolute_error: 1.4574\n",
      "Epoch 260/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.6152 - acc: 0.0000e+00 - mean_squared_error: 3.6152 - mean_absolute_error: 1.4556\n",
      "Epoch 261/300\n",
      "11/11 [==============================] - 0s 602us/step - loss: 3.6110 - acc: 0.0000e+00 - mean_squared_error: 3.6110 - mean_absolute_error: 1.4538\n",
      "Epoch 262/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.6069 - acc: 0.0000e+00 - mean_squared_error: 3.6069 - mean_absolute_error: 1.4521\n",
      "Epoch 263/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 3.6030 - acc: 0.0000e+00 - mean_squared_error: 3.6030 - mean_absolute_error: 1.4504\n",
      "Epoch 264/300\n",
      "11/11 [==============================] - 0s 742us/step - loss: 3.5993 - acc: 0.0000e+00 - mean_squared_error: 3.5993 - mean_absolute_error: 1.4487\n",
      "Epoch 265/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.5957 - acc: 0.0000e+00 - mean_squared_error: 3.5957 - mean_absolute_error: 1.4471\n",
      "Epoch 266/300\n",
      "11/11 [==============================] - 0s 712us/step - loss: 3.5922 - acc: 0.0000e+00 - mean_squared_error: 3.5922 - mean_absolute_error: 1.4455\n",
      "Epoch 267/300\n",
      "11/11 [==============================] - 0s 707us/step - loss: 3.5889 - acc: 0.0000e+00 - mean_squared_error: 3.5889 - mean_absolute_error: 1.4439\n",
      "Epoch 268/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.5858 - acc: 0.0000e+00 - mean_squared_error: 3.5858 - mean_absolute_error: 1.4423\n",
      "Epoch 269/300\n",
      "11/11 [==============================] - 0s 541us/step - loss: 3.5827 - acc: 0.0000e+00 - mean_squared_error: 3.5827 - mean_absolute_error: 1.4408\n",
      "Epoch 270/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 3.5798 - acc: 0.0000e+00 - mean_squared_error: 3.5798 - mean_absolute_error: 1.4393\n",
      "Epoch 271/300\n",
      "11/11 [==============================] - 0s 532us/step - loss: 3.5770 - acc: 0.0000e+00 - mean_squared_error: 3.5770 - mean_absolute_error: 1.4379\n",
      "Epoch 272/300\n",
      "11/11 [==============================] - 0s 737us/step - loss: 3.5743 - acc: 0.0000e+00 - mean_squared_error: 3.5743 - mean_absolute_error: 1.4365\n",
      "Epoch 273/300\n",
      "11/11 [==============================] - 0s 852us/step - loss: 3.5717 - acc: 0.0000e+00 - mean_squared_error: 3.5717 - mean_absolute_error: 1.4351\n",
      "Epoch 274/300\n",
      "11/11 [==============================] - 0s 635us/step - loss: 3.5692 - acc: 0.0000e+00 - mean_squared_error: 3.5692 - mean_absolute_error: 1.4337\n",
      "Epoch 275/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.5668 - acc: 0.0000e+00 - mean_squared_error: 3.5668 - mean_absolute_error: 1.4323\n",
      "Epoch 276/300\n",
      "11/11 [==============================] - 0s 632us/step - loss: 3.5645 - acc: 0.0000e+00 - mean_squared_error: 3.5645 - mean_absolute_error: 1.4310\n",
      "Epoch 277/300\n",
      "11/11 [==============================] - 0s 858us/step - loss: 3.5623 - acc: 0.0000e+00 - mean_squared_error: 3.5623 - mean_absolute_error: 1.4297\n",
      "Epoch 278/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.5601 - acc: 0.0000e+00 - mean_squared_error: 3.5601 - mean_absolute_error: 1.4285\n",
      "Epoch 279/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.5581 - acc: 0.0000e+00 - mean_squared_error: 3.5581 - mean_absolute_error: 1.4272\n",
      "Epoch 280/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.5561 - acc: 0.0000e+00 - mean_squared_error: 3.5561 - mean_absolute_error: 1.4260\n",
      "Epoch 281/300\n",
      "11/11 [==============================] - 0s 497us/step - loss: 3.5543 - acc: 0.0000e+00 - mean_squared_error: 3.5543 - mean_absolute_error: 1.4248\n",
      "Epoch 282/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.5524 - acc: 0.0000e+00 - mean_squared_error: 3.5524 - mean_absolute_error: 1.4237\n",
      "Epoch 283/300\n",
      "11/11 [==============================] - 0s 817us/step - loss: 3.5507 - acc: 0.0000e+00 - mean_squared_error: 3.5507 - mean_absolute_error: 1.4225\n",
      "Epoch 284/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.5491 - acc: 0.0000e+00 - mean_squared_error: 3.5491 - mean_absolute_error: 1.4214\n",
      "Epoch 285/300\n",
      "11/11 [==============================] - 0s 816us/step - loss: 3.5475 - acc: 0.0000e+00 - mean_squared_error: 3.5475 - mean_absolute_error: 1.4203\n",
      "Epoch 286/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.5459 - acc: 0.0000e+00 - mean_squared_error: 3.5459 - mean_absolute_error: 1.4192\n",
      "Epoch 287/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.5444 - acc: 0.0000e+00 - mean_squared_error: 3.5444 - mean_absolute_error: 1.4182\n",
      "Epoch 288/300\n",
      "11/11 [==============================] - 0s 685us/step - loss: 3.5430 - acc: 0.0000e+00 - mean_squared_error: 3.5430 - mean_absolute_error: 1.4172\n",
      "Epoch 289/300\n",
      "11/11 [==============================] - 0s 725us/step - loss: 3.5417 - acc: 0.0000e+00 - mean_squared_error: 3.5417 - mean_absolute_error: 1.4162\n",
      "Epoch 290/300\n",
      "11/11 [==============================] - 0s 895us/step - loss: 3.5404 - acc: 0.0000e+00 - mean_squared_error: 3.5404 - mean_absolute_error: 1.4152\n",
      "Epoch 291/300\n",
      "11/11 [==============================] - 0s 792us/step - loss: 3.5391 - acc: 0.0000e+00 - mean_squared_error: 3.5391 - mean_absolute_error: 1.4142\n",
      "Epoch 292/300\n",
      "11/11 [==============================] - 0s 801us/step - loss: 3.5379 - acc: 0.0000e+00 - mean_squared_error: 3.5379 - mean_absolute_error: 1.4132\n",
      "Epoch 293/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.5367 - acc: 0.0000e+00 - mean_squared_error: 3.5367 - mean_absolute_error: 1.4123\n",
      "Epoch 294/300\n",
      "11/11 [==============================] - 0s 841us/step - loss: 3.5356 - acc: 0.0000e+00 - mean_squared_error: 3.5356 - mean_absolute_error: 1.4114\n",
      "Epoch 295/300\n",
      "11/11 [==============================] - 0s 907us/step - loss: 3.5346 - acc: 0.0000e+00 - mean_squared_error: 3.5346 - mean_absolute_error: 1.4105\n",
      "Epoch 296/300\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3.5335 - acc: 0.0000e+00 - mean_squared_error: 3.5335 - mean_absolute_error: 1.4096\n",
      "Epoch 297/300\n",
      "11/11 [==============================] - 0s 701us/step - loss: 3.5325 - acc: 0.0000e+00 - mean_squared_error: 3.5325 - mean_absolute_error: 1.4088\n",
      "Epoch 298/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.5316 - acc: 0.0000e+00 - mean_squared_error: 3.5316 - mean_absolute_error: 1.4079\n",
      "Epoch 299/300\n",
      "11/11 [==============================] - 0s 543us/step - loss: 3.5307 - acc: 0.0000e+00 - mean_squared_error: 3.5307 - mean_absolute_error: 1.4071\n",
      "Epoch 300/300\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3.5298 - acc: 0.0000e+00 - mean_squared_error: 3.5298 - mean_absolute_error: 1.4063\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd',metrics=['mse','mae'])\n",
    "history=model.fit(x_train_new,y_train,batch_size=11,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654],\n",
       "       [58.97654]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
